{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36b8c84fc314970b549a5ccdac76fb7190d06254b4f13830a348ec2d14d43812"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# a recommender system using restricted Boltzmann machines\n",
    "#### references: Fischer and Igel, 2012, An Introduction to Restricted Boltzmann Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "source": [
    "# . . download the movielens dataset\n",
    "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "!unzip ml-100k.zip\n",
    "!ls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . prepare the training and test sets\n",
    "# . . the separator is tab\n",
    "train_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
    "test_set =  pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
    "\n",
    "# . . convert to numpy arrays\n",
    "train_set = np.array(train_set, dtype='int')\n",
    "test_set = np.array(test_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . get the number of users movies and users\n",
    "# . . take the maximum user id in the training set\n",
    "num_users  = int(max(max(train_set[:,0], ), max(test_set[:, 0])))\n",
    "num_movies = int(max(max(train_set[:,1], ), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . convert the data into an array where each row represents a user and eadch column represents a movie\n",
    "def prep_data(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, num_users +1):\n",
    "        # . . get the movies and ratings belong the current user\n",
    "        # . . indexes of movies that were rated\n",
    "        id_movies  = data[:,1] [data[:,0] == id_users]\n",
    "        # . , the ratings\n",
    "        id_ratings = data[:,2] [data[:,0] == id_users]\n",
    "        ratings = np.zeros(num_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . prepare the training and validation sets\n",
    "train_set = prep_data(train_set)\n",
    "test_set  = prep_data(test_set)\n",
    "\n",
    "# . . transform the tarining and validation sets to Torch tensors\n",
    "train_set = torch.FloatTensor(train_set)\n",
    "test_set  = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . convert the traning ratings into binary form: 1: liked, 0: not liked\n",
    "# . . zero in the data means it is not rated: make it -1\n",
    "# . . in the prepared dataset, zero means the user did not like the movie\n",
    "# . . the training set\n",
    "train_set[train_set == 0] = -1\n",
    "train_set[train_set == 1] = 0\n",
    "train_set[train_set == 2] = 0\n",
    "train_set[train_set == 3] = 1\n",
    "# . . the validation set\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set == 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . the hyperparameters\n",
    "num_epoch = 10\n",
    "batch_size = 100\n",
    "# . . the number of hidden nodes\n",
    "num_hidden = 100\n",
    "# . . hte k-steps of the contrasive divergence\n",
    "num_steps = 10\n",
    "# . . the fixed parameters\n",
    "# . . the number of visible nodes: the number of movies\n",
    "num_visible = len(train_set[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . the restricted Boltzmann machine: an energy-based model\n",
    "# . . a restricted Boltzmann machine is a probabilistic graphical model\n",
    "class RBM():\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        # . . the weight matrix\n",
    "        self.W = torch.randn(num_hidden, num_visible)\n",
    "        # . . the bias of the hidden nodes\n",
    "        self.a = torch.randn(1, num_hidden)\n",
    "        # . . the bias of the visible nodes\n",
    "        self.b = torch.randn(1, num_visible)\n",
    "\n",
    "    # . . compute the probability of the hidden nodes given the visible nodes\n",
    "    def sample_hidden(self, v):\n",
    "        # . . W @ v\n",
    "        wv  = torch.mm(v, self.W.t())\n",
    "        \n",
    "        # . . W @ v + a\n",
    "        wva = wv + self.a.expand_as(wv)        \n",
    "\n",
    "        # . . the probability of the hidden node will be activated given the visible node\n",
    "        prob_hidden = torch.sigmoid(wva)\n",
    "\n",
    "        # . . draw a binary random number (0 or 1) from a Bernoulli distribution\n",
    "        # . . to decide whether to activate the hidden neuron or not according to its probability\n",
    "        sample_hidden = torch.bernoulli(prob_hidden)\n",
    "\n",
    "        return prob_hidden, sample_hidden\n",
    "\n",
    "    # . . compute the probability of the visible nodes given the hidden nodes\n",
    "    def sample_visible(self, h):\n",
    "        # . . W @ y\n",
    "        wh  = torch.mm(h, self.W)\n",
    "        \n",
    "        # . . W @ h + b\n",
    "        whb = wh + self.b.expand_as(wh)\n",
    "        \n",
    "        # . . the probability of the hidden will be activated node given the visible node\n",
    "        prob_visible = torch.sigmoid(whb)\n",
    "\n",
    "        # . . draw a binary random number (0 or 1) from a Bernoulli distribution\n",
    "        # . . to decide whether to activate the visible neuron or not according to its probability\n",
    "        sample_visible = torch.bernoulli(prob_visible)\n",
    "\n",
    "        return prob_visible, sample_visible\n",
    "\n",
    "\n",
    "    # . . train the RBM with the contrasive divergence\n",
    "    # . . the contrasive divergence approximates the log likelihood gradient\n",
    "    # . . we are updating weights to minimazie the energy (i.e., maximize the log lokelihood)\n",
    "    # . . v0: vector of observations: movie ratings by the user\n",
    "    # . . vk: visible nodes obtained after k sampling (kth-step contrasive divergence)\n",
    "    # . . ph0: vector of prior probabilities of hidden given the movie ratings (v0)\n",
    "    # . . phk: vector of probabilities of hidden given the movie ratings (vk) after k-sampling\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        # . .step 8,9 , and 10 of the paper (see the reference at top)\n",
    "        # . . update the weights\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()                \n",
    "        # . . update the bias of visible nodes\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        # . . update the bias of hidden nodes\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . instantiate the model\n",
    "rbm = RBM(num_visible, num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Train loss: tensor(2.1906)\n",
      "Epoch: 2 Train loss: tensor(2.1173)\n",
      "Epoch: 3 Train loss: tensor(2.1135)\n",
      "Epoch: 4 Train loss: tensor(2.1134)\n",
      "Epoch: 5 Train loss: tensor(2.1133)\n",
      "Epoch: 6 Train loss: tensor(2.1149)\n",
      "Epoch: 7 Train loss: tensor(2.1145)\n",
      "Epoch: 8 Train loss: tensor(2.1150)\n",
      "Epoch: 9 Train loss: tensor(2.1134)\n",
      "Epoch: 10 Train loss: tensor(2.1126)\n"
     ]
    }
   ],
   "source": [
    "# . . train the RBM with k-step contrasive divergence\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train_loss = 0\n",
    "    loss = []\n",
    "    batch = 0\n",
    "    for id_user in range(0, num_users - batch_size, batch_size):    \n",
    "        # . . do not change the targets: v0\n",
    "        v0 = train_set[id_user: id_user + batch_size]\n",
    "        vk = train_set[id_user: id_user + batch_size]\n",
    "        \n",
    "        ph0, _ = rbm.sample_hidden(v0)\n",
    "        # . . the k-steps of the contrasive divergence: random walk (Gibbs sampling)\n",
    "        for k in range(num_steps):\n",
    "          _, hk = rbm.sample_hidden(vk)\n",
    "          _, vk = rbm.sample_visible(hk)\n",
    "          # . . do no include the -1 ratings (movies theuser didn't watch) in the training\n",
    "          vk[v0<0] = v0[v0<0]\n",
    "        phk, _ = rbm.sample_hidden(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        # . . the free energy of the system: (representative)\n",
    "        # . . only include the existing ratings in the loss\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        batch += 1.\n",
    "    print('Epoch: '+str(epoch)+' Train loss: '+str(train_loss/batch))"
   ]
  },
  {
   "source": [
    "# . . test the trained network\n",
    "test_loss = 0\n",
    "batch = 0.\n",
    "for id_user in range(num_users):    \n",
    "    # . . do not change the targets: vt\n",
    "    # . . predict users sequentially\n",
    "    v  = train_set[id_user: id_user + 1]\n",
    "    vt = test_set[ id_user: id_user + 1]\n",
    "    \n",
    "    # . . we only need a single step: this is a blind walk\n",
    "    # . . take only the existing ratings\n",
    "    if len(vt[vt >= 0]) > 0:\n",
    "      _, h = rbm.sample_hidden(v)\n",
    "      _, v = rbm.sample_visible(h)\n",
    "\n",
    "      # . . the free energy of the system: (representative)\n",
    "      # . . only include the existing ratings in the loss\n",
    "      test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
    "      # . . update the batch counter\n",
    "      batch += 1.\n",
    "print('Test loss: '+str(test_loss/batch))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: tensor(2.2351)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}